{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  must people  world \n",
      "  1568   1291   1128 \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# When using for the first time, use nltk.download() to download needed stuff\n",
    "\n",
    "# Takes the preloaded state of the union text and tokenizes it into a list of words\n",
    "words = [w for w in nltk.corpus.state_union.words() if w.isalpha()]\n",
    "\n",
    "# Removes stopwords (i.e. 'the', 'a', 'is', etc) from the word list\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "words = [w for w in words if w.lower() not in stopwords]\n",
    "\n",
    "# Shows a frequency distribution of the top 3 words used in the text and shows how many times 'America' (case sensitive) is used\n",
    "fd = nltk.FreqDist(words)\n",
    "fd.tabulate(3)\n",
    "fd[\"America\"]\n",
    "\n",
    "# Creates frequency distribution for text all in lowecase\n",
    "lower_fd = nltk.FreqDist([w.lower() for w in fd])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'neg': 0.305, 'neu': 0.65, 'pos': 0.045, 'compound': -0.886},\n",
       " {'neg': 0.052, 'neu': 0.872, 'pos': 0.076, 'compound': -0.0258},\n",
       " {'neg': 0.074, 'neu': 0.772, 'pos': 0.154, 'compound': 0.34},\n",
       " {'neg': 0.162, 'neu': 0.718, 'pos': 0.121, 'compound': -0.3818},\n",
       " {'neg': 0.093, 'neu': 0.907, 'pos': 0.0, 'compound': -0.5106},\n",
       " {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0},\n",
       " {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "test_par = \"Former President Donald J. Trump averted a financial disaster on Monday, reaching a deal that will spare him from paying a $454 million judgment in his civil fraud case while he appeals the penalty. The lifeline came in the form of a bond that will prevent New York’s attorney general, who brought the lawsuit that led to the judgment, from collecting the $454 million until Mr. Trump’s appeal is resolved. The attorney general, Letitia James, accused Mr. Trump of fraudulently inflating his net worth by as much as $2 billion, and a judge ruled in her favor. Mr. Trump secured the bond after an appeals court last week granted his request to lower the bond amount, setting it at $175 million and staving off a financial crisis for Mr. Trump. He otherwise would have had to post a bond for the full $454 million, which his lawyers declared a “practical impossibility.” Had he failed to do so, Ms. James could have frozen his bank accounts. The clock had been ticking. When the appeals court ruled last week, it gave him 10 days to line up the bond, making Thursday the deadline.\"\n",
    "test_sentences = sent_tokenize(test_par)\n",
    "polarity_scores = []\n",
    "for sentence in test_sentences:\n",
    "    polarity_scores.append(vader.polarity_scores(sentence))\n",
    "polarity_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.125, 'neu': 0.808, 'pos': 0.067, 'compound': -0.9325}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_thing = vader.polarity_scores(test_par)\n",
    "whole_thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trey\\AppData\\Local\\Temp\\ipykernel_9752\\264045528.py:7: UserWarning: Only searches using the function get_news support date ranges. Review the documentation for get_news_by_topic for a partial workaround. \n",
      "Start date and end date will be ignored\n",
      "  news = google_news.get_news_by_topic('NATION')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gnews import GNews\n",
    "\n",
    "gnews = GNews()\n",
    "google_news = GNews(language='en', country='US')\n",
    "google_news.start_date = (2024, 3, 27)\n",
    "google_news.end_date = (2024, 4, 2)\n",
    "news = google_news.get_news_by_topic('NATION')\n",
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
