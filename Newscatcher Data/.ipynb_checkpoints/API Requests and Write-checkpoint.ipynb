{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9826f850-2ccf-47de-972e-30a22ad96aae",
   "metadata": {},
   "source": [
    "One API call can bring a maximum of 100 articles, so set page_size parameter to 100. \n",
    "\n",
    "To use this notebook to make a single API call: just change the variable \"query\" to whatever you want to search for and run the following 2 cells in order. Remember to uncomment the line that actually does the API request! I'm just keeping it commented out to avoid accidentally calling it when I don't mean to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "826bab69-1c56-45ea-b001-e555739a492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7c4a179-5b56-403a-a411-9fee53b3b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"education\"\n",
    "page_number = 1\n",
    "\n",
    "url = \"https://api.newscatcherapi.com/v2/search\"\n",
    "key = \"klBfLpBs_WnisScAvUIg8YIOAEbIcirA1-GQZBfOgnE\"\n",
    "# Sources: NYT, WaPo, CNN, FOX, ABC, CBS, NBC, BBC\n",
    "sources = [\"nytimes.com\", \n",
    "           \"washingtonpost.com\", \n",
    "           \"cnn.com\", \n",
    "           \"foxnews.com\", \n",
    "           \"abcnews.go.com\", \n",
    "           \"cbsnews.com\", \n",
    "           \"nbcnews.com\", \n",
    "           \"bbc.com/news\"]\n",
    "\n",
    "querystring = {\"q\":query,\n",
    "               \"lang\":\"en\",\n",
    "               \"sort_by\":\"relevancy\",\n",
    "               \"sources\":sources,\n",
    "               \"page\":page_number,\n",
    "               \"page_size\":\"100\"}\n",
    "\n",
    "headers = {\n",
    "    \"x-api-key\": key\n",
    "    }\n",
    "\n",
    "#response = requests.request(\"GET\", url, headers=headers, params=querystring)    # we're getting our response in HTTP format\n",
    "json_response = response.json()    # Convert HTTP format to JSON format\n",
    "\n",
    "# Save HTTP content\n",
    "with open(query+\"_\"+str(page_number)+\"_response.txt\", \"w\") as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "# Save JSON content\n",
    "with open(query+\"_\"+str(page_number)+\"_response.json\", \"w\", encoding=\"utf-8\") as f:    # first param is file name to write to\n",
    "    json.dump(json_response, f, ensure_ascii=False, indent=4)     # the ensure_ascii and indent make the file more legible if opened in VSCode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f9d70-e83a-423e-90b7-5957e17e4623",
   "metadata": {},
   "source": [
    "Below, I'll write some code to call and save multiple API requests at once.\n",
    "\n",
    "To use this one, just change page_number to whichever page you're interested in and run the cell.\n",
    "\n",
    "NOTE: The code below is giving weird results from the sources! It only seems to be taking the very first source listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f12b4f3-beae-459c-b384-2ab456116340",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = [\"Democrat\", \n",
    "              \"Republican\",\n",
    "              \"liberal\",\n",
    "              \"conservative\",\n",
    "              \"Biden\",\n",
    "              \"Trump\",\n",
    "              \"abortion\",\n",
    "              \"gun\",\n",
    "              \"Israel\",\n",
    "              \"economy\",\n",
    "              \"climate\",\n",
    "              \"education\"]\n",
    "\n",
    "page_number = 5\n",
    "\n",
    "url = \"https://api.newscatcherapi.com/v2/search\"\n",
    "key = \"klBfLpBs_WnisScAvUIg8YIOAEbIcirA1-GQZBfOgnE\"\n",
    "# Sources: NYT, WaPo, CNN, FOX, ABC, CBS, NBC, BBC\n",
    "sources = [\"nytimes.com\", \n",
    "           \"washingtonpost.com\", \n",
    "           \"cnn.com\", \n",
    "           \"foxnews.com\", \n",
    "           \"abcnews.go.com\", \n",
    "           \"cbsnews.com\", \n",
    "           \"nbcnews.com\", \n",
    "           \"bbc.com/news\"]\n",
    "headers = {\n",
    "    \"x-api-key\": key\n",
    "    }\n",
    "\n",
    "for current_query in query_list:\n",
    "    querystring = {\"q\":current_query,\n",
    "               \"lang\":\"en\",\n",
    "               \"sort_by\":\"relevancy\",\n",
    "               \"sources\":sources,\n",
    "               \"page\":page_number,\n",
    "               \"page_size\":\"100\"}\n",
    "    \n",
    "    #response = requests.request(\"GET\", url, headers=headers, params=querystring)    # we're getting our response in HTTP format\n",
    "    json_response = response.json()    # Convert HTTP format to JSON format\n",
    "\n",
    "    # Save HTTP content\n",
    "    with open(current_query+\"_\"+str(page_number)+\"_response.txt\", \"w\") as f:\n",
    "        f.write(response.text)\n",
    "\n",
    "    # Save JSON content\n",
    "    with open(current_query+\"_\"+str(page_number)+\"_response.json\", \"w\", encoding=\"utf-8\") as f:    # first param is file name to write to\n",
    "        json.dump(json_response, f, ensure_ascii=False, indent=4)     # the ensure_ascii and indent make the file more legible if opened in VSCode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eba45c-2017-402c-b910-ec98306ffd51",
   "metadata": {},
   "source": [
    "Since I'm having trouble getting the sources to behave right, I'll try this time to loop through and save one page worth of data for each source and each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35995146-13b7-47d1-ac9d-a0d70012a777",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_list = [\"Democrat\", \n",
    "              \"Republican\",\n",
    "              \"liberal\",\n",
    "              \"conservative\",\n",
    "              \"Biden\",\n",
    "              \"Trump\",\n",
    "              \"abortion\",\n",
    "              \"gun\",\n",
    "              \"Israel\",\n",
    "              \"economy\",\n",
    "              \"climate\",\n",
    "              \"education\"]\n",
    "\n",
    "url = \"https://api.newscatcherapi.com/v2/search\"\n",
    "key = \"klBfLpBs_WnisScAvUIg8YIOAEbIcirA1-GQZBfOgnE\"\n",
    "# Sources: NYT, WaPo, CNN, FOX, ABC, CBS, NBC, BBC\n",
    "sources = [\"nytimes.com\", \n",
    "           \"washingtonpost.com\", \n",
    "           \"cnn.com\", \n",
    "           \"foxnews.com\", \n",
    "           \"abcnews.go.com\", \n",
    "           \"cbsnews.com\", \n",
    "           \"nbcnews.com\", \n",
    "           \"bbc.com/news\"]\n",
    "\n",
    "headers = {\n",
    "    \"x-api-key\": key\n",
    "    }\n",
    "\n",
    "for current_query in query_list:\n",
    "    for current_source in sources:\n",
    "        querystring = {\"q\":current_query,\n",
    "                   \"lang\":\"en\",\n",
    "                   \"sort_by\":\"relevancy\",\n",
    "                   \"sources\":current_source,\n",
    "                   \"page\":1,\n",
    "                   \"page_size\":\"100\"}\n",
    "\n",
    "        file_name_txt = current_query+\"_\"+current_source[0:3]+\"_response.txt\"\n",
    "        file_name_json = current_query+\"_\"+current_source[0:3]+\"_response.json\"\n",
    "        \n",
    "        #response = requests.request(\"GET\", url, headers=headers, params=querystring)    # we're getting our response in HTTP format\n",
    "        json_response = response.json()    # Convert HTTP format to JSON format\n",
    "    \n",
    "        # Save HTTP content\n",
    "        with open(file_name_txt, \"w\") as f:\n",
    "            f.write(response.text)\n",
    "    \n",
    "        # Save JSON content\n",
    "        with open(file_name_json, \"w\", encoding=\"utf-8\") as f:    # first param is file name to write to\n",
    "            json.dump(json_response, f, ensure_ascii=False, indent=4)     # the ensure_ascii and indent make the file more legible if opened in VSCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b230e801-aab2-4d3d-a26b-414354c99ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
